{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "TTTP6234 - Assignment3_P101447_HOOYT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQzndHpNWnAt",
        "colab_type": "text"
      },
      "source": [
        "# Assignment #3\n",
        "## Topic: Political Reviews - \n",
        "Name: **Hoo Yee Torng** </br>\n",
        "Matrix: **P101447**\n",
        "\n",
        "## 1.0 IMPORT LIBRARY\n",
        "Import all the library needed and download the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRJqjYPoWnAw",
        "colab_type": "code",
        "outputId": "a4ee17eb-6370-47fe-e305-92ae2d941175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import time\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u0R6AuBWnA2",
        "colab_type": "text"
      },
      "source": [
        "## 2.0 Load Dataset files to be processed\n",
        "download following files and upload to the workspace\n",
        "- [politic_issues_positive_reviews.csv](https://drive.google.com/drive/folders/1SBji6xGIjRWvhm41MKIquDML_d-qsvW9?usp=sharing)\n",
        "- [politic_issues_negative_reviews.csv](https://drive.google.com/drive/folders/1SBji6xGIjRWvhm41MKIquDML_d-qsvW9?usp=sharing) <br/>\n",
        "\n",
        "Create a combined master set of data with class **0 as Negative** review and **1 as Positive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "o9xfoBVDWnA3",
        "colab_type": "code",
        "outputId": "322cbd48-4aca-423c-b5c7-8129b8978fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# READ FROM NEGATIVE REVIEW AND ASSIGN 0 AS CLASS VALUE\n",
        "negative_df = pd.read_csv('politic_issues_negative_reviews.csv')\n",
        "negative_df[\"label\"] = 0\n",
        "print(negative_df.shape)\n",
        "\n",
        "# READ FROM POSITIVE REVIEW AND ASSIGN 1 AS CLASS VALUE\n",
        "positive_df = pd.read_csv('politic_issues_positive_reviews.csv')\n",
        "positive_df[\"label\"] = 1\n",
        "print(positive_df.shape)\n",
        "\n",
        "# APPEND BOTH DATAFRAME AS 1\n",
        "raw_df = positive_df.append(negative_df) \n",
        "\n",
        "# RENAME COLUMN\n",
        "raw_df = raw_df.rename(columns={\"Google Translate\": \"review\"})\n",
        "print(raw_df.shape)\n",
        "\n",
        "raw_df.index = range(100)\n",
        "raw_df['review'].apply(lambda x: len(x.split(' '))).sum()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54, 2)\n",
            "(46, 2)\n",
            "(100, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLxOHMSFWnBI",
        "colab_type": "code",
        "outputId": "80414676-d150-4c02-e9f2-789a37a6d55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "cnt_pro = raw_df['label'].value_counts()\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\n",
        "plt.ylabel('Politic Review', fontsize=12)\n",
        "plt.xlabel('Labels', fontsize=12)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAEGCAYAAABM2KIzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nARRoAAAYQIEGAIABFGgAABjg/wMuowcdSldY+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o4ewuXLWnBP",
        "colab_type": "text"
      },
      "source": [
        "## 3.0 PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IhqS8tFUegB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_words(setence):\n",
        "  text = re.sub(\"[^a-zA-Z]\", \" \", setence)\n",
        "  return(text.lower())\n",
        "\n",
        "def clean_word(sentence):\n",
        "  text = re.sub(r'\\|\\|\\|', r' ', sentence) \n",
        "  text = re.sub(r'http\\S+', r'<URL>', text)\n",
        "  text = text.replace('x', '')\n",
        "  return text\n",
        "\n",
        "def remove_stopword(sentence):\n",
        "    new_line = []\n",
        "    word_tokens = nltk.word_tokenize(sentence)\n",
        "    for w in word_tokens:\n",
        "      if w not in stop_words:\n",
        "        new_line.append(w)\n",
        "    \n",
        "    return (\" \".join(new_line) + \" \").strip()\n",
        "\n",
        "def get_adjective_word(setence):\n",
        "  words = []\n",
        "  pos_spacy = ['ADJ', 'ADV']\n",
        "  pos_nltk = ['JJ','JJR', 'JJS','RB','RBS','RBR']\n",
        "  \n",
        "  ## CHECK BY SPACY FIRST\n",
        "  spacy_words = nlp(u''+setence+'')\n",
        "  for token in spacy_words:\n",
        "    if token.pos_ in pos_spacy:\n",
        "      words.append(token.text)\n",
        "\n",
        "  ## CHECK BY NLTK\n",
        "  nltk_words = nltk.word_tokenize(setence)\n",
        "  for stc in nltk_words:\n",
        "    nltk_token = nltk.pos_tag(nltk.word_tokenize(stc))\n",
        "    if nltk_token[0][1] in pos_nltk and nltk_token[0][0] not in words:\n",
        "      #print(\"NTLK : {}:{}\".format(nltk_token[0][0], nltk_token[0][1]))\n",
        "      words.append(nltk_token[0][0])\n",
        "    \n",
        "  return (\" \".join(words) + \" \").strip()\n",
        "\n",
        "def text_processing(objdf):\n",
        "  for index, row in objdf.iterrows():\n",
        "    selected_review = row['review'].strip()\n",
        "    #print(\"--\")\n",
        "    #print(selected_review)\n",
        "    selected_review = extract_words(selected_review)\n",
        "    selected_review = clean_word(selected_review)\n",
        "    selected_review = remove_stopword(selected_review)\n",
        "    #selected_review = get_adjective_word(selected_review)\n",
        "    objdf.loc[index, \"review\"] = selected_review \n",
        "    #print(objdf.loc[index, \"review\"])\n",
        "  return objdf\n",
        "\n",
        "df = text_processing(raw_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaTfnYYJcgFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_percentage(x):\n",
        "  return \"{0:.2f}%\".format(round(x, 2) * 100)\n",
        "\n",
        "def run_ML(feature_name, xtrain, ytrain, xtest, ytest):\n",
        "\n",
        "  print(\"-----------------------------------------------------------------------------\")\n",
        "  print(\"- \" + feature_name)\n",
        "  print(\"-----------------------------------------------------------------------------\")\n",
        "\n",
        "  if feature_name == \"Doc2Vec\":\n",
        "    clf_dict = {\n",
        "      'GradientBoostingClassifier': GradientBoostingClassifier(n_estimators=100),\n",
        "      'RandomForestClassifier': RandomForestClassifier(n_estimators=100, random_state=0),\n",
        "      'GaussianNB': GaussianNB(),\n",
        "      'ANN': MLPClassifier(solver='adam', hidden_layer_sizes=(10,5), random_state=2, activation='relu', max_iter=5000, learning_rate='invscaling'),\n",
        "      'SVN': svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=2000, decision_function_shape='ovr', random_state=2),\n",
        "      'LinearSVC': LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=30000),\n",
        "      'LogisticRegression': LogisticRegression(random_state=42, max_iter=8000, multi_class='auto', solver='saga'),\n",
        "    }    \n",
        "  else:\n",
        "    clf_dict = {\n",
        "      'GradientBoostingClassifier': GradientBoostingClassifier(n_estimators=100),\n",
        "      'RandomForestClassifier': RandomForestClassifier(n_estimators=100, random_state=0),\n",
        "      'MultinomialNB': MultinomialNB(),\n",
        "      'ANN': MLPClassifier(solver='adam', hidden_layer_sizes=(10,5), random_state=2, activation='relu', max_iter=5000, learning_rate='invscaling'),\n",
        "      'SVN': svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=2000, decision_function_shape='ovr', random_state=2),\n",
        "      'LinearSVC': LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=30000),\n",
        "      'LogisticRegression': LogisticRegression(random_state=42, max_iter=8000, multi_class='auto', solver='saga'),\n",
        "    }\n",
        "\n",
        "  for name, clf in clf_dict.items():\n",
        "    clf.fit(xtrain, ytrain) \n",
        "    pred = clf.predict(xtest)\n",
        "    print(\"-- \" + name)\n",
        "    print('Testing accuracy: {}'.format(show_percentage(accuracy_score(ytest, pred))))\n",
        "    print('Testing F1 score: {}'.format(show_percentage(f1_score(ytest, pred, average='macro'))))\n",
        "    print('Testing Precision score: {}'.format(show_percentage(precision_score(ytest, pred, average='macro'))))\n",
        "    print('Testing Recall score: {} \\n'.format(show_percentage(recall_score(ytest, pred, average='macro'))))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzR6Ep1hWnBn",
        "colab_type": "code",
        "outputId": "5258b7e8-8bf8-41f3-8a13-7288b1574cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "features = df['review'].values\n",
        "classes = df['label'].values\n",
        "\n",
        "sentences_train, sentences_test, yy_train, yy_test = train_test_split(features, classes, test_size=0.1, random_state=42, shuffle=True)\n",
        "\n",
        "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(sentences_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(sentences_test.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 100\n",
            "Number of rows in the training set: 90\n",
            "Number of rows in the test set: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDVKSbluWnBm",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 FEATURE - BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGgzmvqqg-QQ",
        "colab_type": "code",
        "outputId": "22255be4-3678-4d5a-fe50-57f7e3949b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "BOW = CountVectorizer()\n",
        "BOW.fit(sentences_train)\n",
        "XX_train = BOW.transform(sentences_train)\n",
        "XX_test  = BOW.transform(sentences_test)\n",
        "run_ML(\"BOW\", XX_train, yy_train, XX_test, yy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------\n",
            "- BOW\n",
            "-----------------------------------------------------------------------------\n",
            "-- GradientBoostingClassifier\n",
            "Testing accuracy: 50.00%\n",
            "Testing F1 score: 45.00%\n",
            "Testing Precision score: 72.00%\n",
            "Testing Recall score: 58.00% \n",
            "\n",
            "-- RandomForestClassifier\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n",
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- MultinomialNB\n",
            "Testing accuracy: 60.00%\n",
            "Testing F1 score: 58.00%\n",
            "Testing Precision score: 75.00%\n",
            "Testing Recall score: 67.00% \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- ANN\n",
            "Testing accuracy: 70.00%\n",
            "Testing F1 score: 70.00%\n",
            "Testing Precision score: 79.00%\n",
            "Testing Recall score: 75.00% \n",
            "\n",
            "-- SVN\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n",
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- LinearSVC\n",
            "Testing accuracy: 70.00%\n",
            "Testing F1 score: 70.00%\n",
            "Testing Precision score: 79.00%\n",
            "Testing Recall score: 75.00% \n",
            "\n",
            "-- LogisticRegression\n",
            "Testing accuracy: 60.00%\n",
            "Testing F1 score: 58.00%\n",
            "Testing Precision score: 75.00%\n",
            "Testing Recall score: 67.00% \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2gjWIknWnBv",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 FEATURE-TF - IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlGFChWNWnBw",
        "colab_type": "code",
        "outputId": "01a66e82-0061-4cdd-dcc0-375c00611b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "TFIDF = TfidfVectorizer()\n",
        "TFIDF.fit_transform(sentences_train)\n",
        "XXX_train = TFIDF.transform(sentences_train)\n",
        "XXX_test  = TFIDF.transform(sentences_test)\n",
        "\n",
        "run_ML(\"TF-IDF\", XXX_train, yy_train, XXX_test, yy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------\n",
            "- TF-IDF\n",
            "-----------------------------------------------------------------------------\n",
            "-- GradientBoostingClassifier\n",
            "Testing accuracy: 60.00%\n",
            "Testing F1 score: 58.00%\n",
            "Testing Precision score: 75.00%\n",
            "Testing Recall score: 67.00% \n",
            "\n",
            "-- RandomForestClassifier\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n",
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- MultinomialNB\n",
            "Testing accuracy: 50.00%\n",
            "Testing F1 score: 45.00%\n",
            "Testing Precision score: 72.00%\n",
            "Testing Recall score: 58.00% \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- ANN\n",
            "Testing accuracy: 70.00%\n",
            "Testing F1 score: 70.00%\n",
            "Testing Precision score: 79.00%\n",
            "Testing Recall score: 75.00% \n",
            "\n",
            "-- SVN\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n",
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- LinearSVC\n",
            "Testing accuracy: 70.00%\n",
            "Testing F1 score: 70.00%\n",
            "Testing Precision score: 79.00%\n",
            "Testing Recall score: 75.00% \n",
            "\n",
            "-- LogisticRegression\n",
            "Testing accuracy: 50.00%\n",
            "Testing F1 score: 45.00%\n",
            "Testing Precision score: 72.00%\n",
            "Testing Recall score: 58.00% \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luCQm8-V_VlU",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Feature - Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Yvw434AQcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "cores = multiprocessing.cpu_count()\n",
        "from tqdm import tqdm\n",
        "from sklearn import utils\n",
        "\n",
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word.lower())\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmHRO1nj_fY5",
        "colab_type": "code",
        "outputId": "cf75fbad-bd3d-417e-90af-31488ba0058c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# SPLIT TO 9:1\n",
        "doc2vec_train, doc2vec_test = train_test_split(df, test_size=0.1, random_state=42, shuffle=True)\n",
        "\n",
        "# CONVERT TO DOC TO VEC FORMAT\n",
        "train_tagged = doc2vec_train.apply(lambda r: TaggedDocument(words=tokenize_text(r['review']), tags=[r.label]), axis=1)\n",
        "test_tagged = doc2vec_test.apply(lambda r: TaggedDocument(words=tokenize_text(r['review']), tags=[r.label]), axis=1)\n",
        "\n",
        "\n",
        "# dm :: dm=1, 'distributed memory' (PV-DM), 0=BOW\n",
        "# vector_size :: Dimensionality of the feature vectors\n",
        "# negative ::  0 = no negative sampling is used.\n",
        "# hs :: If 1, hierarchical softmax will be used for model training. If set to 0, and negative is non-zero, negative sampling will be used.\n",
        "# min_count (int, optional) – Ignores all words with total frequency lower than this.\n",
        "# sample (float, optional) – The threshold for configuring which higher-frequency words are randomly downsampled, useful range is (0, 1e-5).\n",
        "# workers (int, optional) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
        "\n",
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample=0, workers=cores)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:00<00:00, 143258.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSBx7K7OvuI5",
        "colab_type": "code",
        "outputId": "de44ecdd-94fe-4581-ea8b-2ffaf82e8d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=100)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:00<00:00, 257846.56it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 19556.90it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 23430.41it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 23346.36it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 25085.55it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 26589.23it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 26083.98it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 21908.73it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 30143.52it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 24394.94it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 97718.71it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 135397.19it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 157220.89it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 21759.70it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 26392.18it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 25791.70it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 118706.72it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 215583.87it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 47009.63it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 77116.93it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 405029.36it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 54550.20it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 68521.94it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 62508.26it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 26414.34it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 24346.17it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 114982.44it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 25384.13it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 21643.68it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 24592.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14.7 s, sys: 1.28 s, total: 15.9 s\n",
            "Wall time: 16.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_3pv7dawC0N",
        "colab_type": "code",
        "outputId": "d8ac086c-b8c3-4927-ff67-e7ba5a2c6f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors\n",
        "\n",
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
        "\n",
        "run_ML(\"Doc2Vec\", X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------\n",
            "- Doc2Vec\n",
            "-----------------------------------------------------------------------------\n",
            "-- GradientBoostingClassifier\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 38.00%\n",
            "Testing Precision score: 44.00%\n",
            "Testing Recall score: 46.00% \n",
            "\n",
            "-- RandomForestClassifier\n",
            "Testing accuracy: 50.00%\n",
            "Testing F1 score: 45.00%\n",
            "Testing Precision score: 72.00%\n",
            "Testing Recall score: 58.00% \n",
            "\n",
            "-- GaussianNB\n",
            "Testing accuracy: 50.00%\n",
            "Testing F1 score: 49.00%\n",
            "Testing Precision score: 50.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- ANN\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n",
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- SVN\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n",
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- LinearSVC\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n",
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n",
            "-- LogisticRegression\n",
            "Testing accuracy: 40.00%\n",
            "Testing F1 score: 29.00%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Precision score: 20.00%\n",
            "Testing Recall score: 50.00% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsS02GXbWnB2",
        "colab_type": "text"
      },
      "source": [
        "### REPORT :<br>\n",
        "\n",
        "#### BOW\n",
        "\n",
        "| Classifier | Accuracy | F1 | Precision | Recall | \n",
        "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
        "| Gradient Boosting | 50.00% | 45.00% | 72.00% | 58.00% |\n",
        "| Random Forest | 40.00% | 29.00% | 20.00% | 50.00% |\n",
        "| Multinomial NB | 60.00% | 58.00% | 75.00% | 67.00% |\n",
        "| ANN | 70.00% | 70.00% | 79.00% | 75.00% |\n",
        "| SVN | 40.00% | 29.00% | 20.00% | 50.00% |\n",
        "| Linear | 70.00% | 70.00% | 79.00% | 75.00% |\n",
        "| Logistic Regression | 60.00% | 58.00% | 75.00% | 67.00% |\n",
        "\n",
        "#### TF-IDF\n",
        "\n",
        "| Classifier | Accuracy | F1 | Precision | Recall | \n",
        "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
        "| Gradient Boosting | 50.00% | 49.00% | 55.00% | 54.00% |\n",
        "| Random Forest | 40.00% | 29.00% | 20.00% | 50.00% |\n",
        "| Multinomial NB | 50.00% | 45.00% | 72.00% | 58.00% |\n",
        "| ANN | 70.00% | 70.00% | 79.00% | 75.00% |\n",
        "| SVN | 40.00% | 29.00% | 20.00% | 50.00% |\n",
        "| Linear | 70.00% | 70.00% | 79.00% | 75.00% |\n",
        "| Logistic Regression | 50.00% | 45.00% | 72.00% | 58.00% |\n",
        "\n",
        "#### DOC2VEC\n",
        "\n",
        "| Classifier | Accuracy | F1 | Precision | Recall | \n",
        "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
        "| Gradient Boosting | 40.00% | 38.00% | 44.00% | 46.00% |\n",
        "| Random Forest | 50.00% | 45.00% | 72.00% | 58.00% |\n",
        "| Gaussian NB | 50.00% | 49.00% | 50.00% | 50.00% |\n",
        "| ANN | 40.00% | 29.00% | 20.00% | 50.00% |\n",
        "| SVN | 40.00% | 29.00% | 20.00% | 50.00% |\n",
        "| Linear | 40.00% | 29.00% | 20.00% | 50.00% |\n",
        "| Logistic Regression | 40.00% | 29.00% | 20.00% | 50.00% |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRNdnL2UdCsl",
        "colab_type": "text"
      },
      "source": [
        "**Answer**\n",
        "* #1 - ANN with BOW and TD-IDF\n",
        "* #2 - Linear with BOW and TD-IDF\n",
        "\n"
      ]
    }
  ]
}